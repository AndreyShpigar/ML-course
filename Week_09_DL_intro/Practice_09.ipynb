{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Введение в нейронные сети"
      ],
      "metadata": {
        "id": "gIYLVadL8cKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBKsX09J7dPy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "_ = torch.manual_seed(SEED)"
      ],
      "metadata": {
        "id": "pdyuJfNZMkjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "LR = 0.1\n",
        "INPUT_SIZE = 2\n",
        "HIDDEN_SIZE = 8\n",
        "OUTPUT_SIZE = 1"
      ],
      "metadata": {
        "id": "X8s2CugsNmI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgkSBdkm7dPz"
      },
      "source": [
        "## Создание и визуализация датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeMFjxxq7dP0"
      },
      "outputs": [],
      "source": [
        "X, Y = make_moons(n_samples=1000, noise=0.125, random_state=42)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=SEED)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "plt.scatter(X_train_scaled[Y_train == 0, 0], X_train_scaled[Y_train == 0, 1],\n",
        "           color='red', label='0')\n",
        "plt.scatter(X_train_scaled[Y_train == 1, 0], X_train_scaled[Y_train == 1, 1],\n",
        "           color='blue', label='1')\n",
        "plt.title('Dataset')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVgY6Bm_7dP0"
      },
      "source": [
        "#### Архитектура сети:\n",
        "$$\n",
        "\\begin{align*}\n",
        "z_1 &= X \\cdot W_1 + b_1 \\\\\n",
        "a_1 &= \\text{ReLU}(z_1) \\\\\n",
        "z_2 &= a_1 \\cdot W_2 + b_2 \\\\\n",
        "a_2 &= \\sigma(z_2)\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "#### Функции активации:\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\text{ReLU}(x) &= \\max(0, x) \\\\\n",
        "\\sigma(x) &= \\frac{1}{1 + e^{-x}}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "#### Функция потерь (Binary Cross-Entropy):\n",
        "$$\n",
        "L = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\cdot \\log(\\hat{y}_i) + (1 - y_i) \\cdot \\log(1 - \\hat{y}_i) \\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4WzBEFN7dP0"
      },
      "outputs": [],
      "source": [
        "class Linear_NN_numpy:\n",
        "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
        "        # Kaiming Initialization для ReLU\n",
        "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size)\n",
        "        self.b1 = np.zeros((1, hidden_size))\n",
        "\n",
        "        # Xavier Initialization для Sigmoid\n",
        "        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(1.0 / hidden_size)\n",
        "        self.b2 = np.zeros((1, output_size))\n",
        "\n",
        "        self.lr = learning_rate\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def relu_derivative(self, x):\n",
        "        return (x > 0).astype(float)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-np.clip(x, -666, 666)))\n",
        "\n",
        "    def binary_cross_entropy(self, y_true, y_pred):\n",
        "        y_true = y_true.reshape(-1, 1)\n",
        "        epsilon = 1e-12\n",
        "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "        loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "        return loss\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.a1 = self.relu(self.z1)\n",
        "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
        "        self.a2 = self.sigmoid(self.z2)\n",
        "        return self.a2\n",
        "\n",
        "    def backward(self, X, y_true, y_pred):\n",
        "        m = X.shape[0]\n",
        "        y_true = y_true.reshape(-1, 1)\n",
        "\n",
        "        # градиенты выходного слоя\n",
        "        dz2 = y_pred - y_true.reshape(-1, 1)\n",
        "        dW2 = (1/m) * np.dot(self.a1.T, dz2)\n",
        "        db2 = (1/m) * np.sum(dz2, axis=0, keepdims=True)\n",
        "\n",
        "        # градиенты скрытого слоя\n",
        "        dz1 = np.dot(dz2, self.W2.T) * self.relu_derivative(self.z1)\n",
        "        dW1 = (1/m) * np.dot(X.T, dz1)\n",
        "        db1 = (1/m) * np.sum(dz1, axis=0, keepdims=True)\n",
        "\n",
        "        # обновление весов\n",
        "        self.W2 -= self.lr * dW2\n",
        "        self.b2 -= self.lr * db2\n",
        "        self.W1 -= self.lr * dW1\n",
        "        self.b1 -= self.lr * db1\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        y_pred = self.forward(X)\n",
        "        return (y_pred > threshold).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_NN_numpy = Linear_NN_numpy(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, output_size=OUTPUT_SIZE, learning_rate=LR)\n",
        "\n",
        "learning_history_numpy = {\n",
        "    'loss': [],\n",
        "    'accuracy_train': [],\n",
        "    'accuracy_test': [],\n",
        "    'W1_norm': [],\n",
        "    'W2_norm': []\n",
        "}"
      ],
      "metadata": {
        "id": "MRdJ9h_f_SVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    # прямой проход\n",
        "    Y_pred = model_NN_numpy.forward(X_train_scaled)\n",
        "\n",
        "    # вычисление значения функции потерь\n",
        "    loss = model_NN_numpy.binary_cross_entropy(Y_train, Y_pred)\n",
        "\n",
        "    # обратный проход\n",
        "    model_NN_numpy.backward(X_train_scaled, Y_train, Y_pred)\n",
        "\n",
        "    # оценка качества\n",
        "    Y_pred_train = model_NN_numpy.predict(X_train_scaled)\n",
        "    accuracy_train = np.mean(Y_pred_train.flatten() == Y_train)\n",
        "\n",
        "    Y_pred_test = model_NN_numpy.predict(X_test_scaled)\n",
        "    accuracy_test = np.mean(Y_pred_test.flatten() == Y_test)\n",
        "\n",
        "    # сохранение истории\n",
        "    learning_history_numpy['loss'].append(loss)\n",
        "    learning_history_numpy['accuracy_train'].append(accuracy_train)\n",
        "    learning_history_numpy['accuracy_test'].append(accuracy_test)\n",
        "    learning_history_numpy['W1_norm'].append(np.linalg.norm(model_NN_numpy.W1))\n",
        "    learning_history_numpy['W2_norm'].append(np.linalg.norm(model_NN_numpy.W2))\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch:4d}, Loss: {loss:.4f}, Train Acc: {accuracy_train:.4f}, Test Acc: {accuracy_test:.4f}')"
      ],
      "metadata": {
        "id": "KrJzht60_pt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Визуализация процесса обучения НС"
      ],
      "metadata": {
        "id": "4JbmKeTlEfoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "# Loss\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(learning_history_numpy['loss'], 'b-', linewidth=2)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend(['Loss'])\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(learning_history_numpy['accuracy_train'], 'g-', linewidth=2, label='Train')\n",
        "plt.plot(learning_history_numpy['accuracy_test'], 'r-', linewidth=2, label='Test')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Weights\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(learning_history_numpy['W1_norm'], 'purple', linewidth=2, label='||W1||')\n",
        "plt.plot(learning_history_numpy['W2_norm'], 'orange', linewidth=2, label='||W2||')\n",
        "plt.title('Weights')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Weights')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)"
      ],
      "metadata": {
        "id": "cpPo7_FUGAyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация границы принятия решений\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    \"\"\"Визуализация границы принятия решений нейронной сети\"\"\"\n",
        "    h = 0.02\n",
        "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
        "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdBu)\n",
        "    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu, edgecolors='black', s=30)\n",
        "    plt.colorbar(scatter)\n",
        "    plt.show()\n",
        "\n",
        "plot_decision_boundary(model_NN_numpy, X_test_scaled, Y_test)"
      ],
      "metadata": {
        "id": "qt6JLmXKEcWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание НС с использованием PyTorch"
      ],
      "metadata": {
        "id": "MxIblL89IV4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear_NN_torch(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Linear_NN_torch, self).__init__()\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, output_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        nn.init.kaiming_normal_(self.network[0].weight, nonlinearity='relu')\n",
        "        nn.init.constant_(self.network[0].bias, 0)\n",
        "\n",
        "        nn.init.xavier_normal_(self.network[2].weight)\n",
        "        nn.init.constant_(self.network[2].bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ],
      "metadata": {
        "id": "ZLUwaU8QIevo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# преобразуем данные в torch tensor тип\n",
        "X_train_torch = torch.FloatTensor(X_train_scaled)\n",
        "Y_train_torch = torch.FloatTensor(Y_train).reshape(-1, 1)\n",
        "X_test_torch = torch.FloatTensor(X_test_scaled)\n",
        "Y_test_torch = torch.FloatTensor(Y_test).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "ytCf0d8CIt6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nn_torch = Linear_NN_torch(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, output_size=OUTPUT_SIZE)\n",
        "\n",
        "learning_history_torch = {\n",
        "    'loss': [],\n",
        "    'accuracy_train': [],\n",
        "    'accuracy_test': [],\n",
        "    'W1_norm': [],\n",
        "    'W2_norm': []\n",
        "}\n",
        "\n",
        "# Задаем Loss и оптимизатор\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model_nn_torch.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "IE8IiKdEIxaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    # прямой проход\n",
        "    y_pred = model_nn_torch(X_train_torch)\n",
        "\n",
        "    # вычисление значения функции потерь\n",
        "    loss = criterion(y_pred, Y_train_torch)\n",
        "\n",
        "    # обратный проход\n",
        "    optimizer.zero_grad()  # обнуляем градиенты потому что torch по дефолту накапливает значения градиентов\n",
        "    loss.backward()        # вычисляем градиенты\n",
        "    optimizer.step()       # обновляем веса\n",
        "\n",
        "    # не используем автоград при расчете метрики (а так же при валидации и инференсе)\n",
        "    with torch.no_grad():\n",
        "        # train accuracy\n",
        "        train_pred = (y_pred > 0.5).float()\n",
        "        train_accuracy = (train_pred == Y_train_torch).float().mean()\n",
        "\n",
        "        # test accuracy\n",
        "        test_outputs = model_nn_torch(X_test_torch)\n",
        "        test_pred = (test_outputs > 0.5).float()\n",
        "        test_accuracy = (test_pred == Y_test_torch).float().mean()\n",
        "\n",
        "        # weights\n",
        "        W1_norm = torch.norm(model_nn_torch.network[0].weight).item()\n",
        "        W2_norm = torch.norm(model_nn_torch.network[2].weight).item()\n",
        "\n",
        "    # сохранение истории\n",
        "    learning_history_torch['loss'].append(loss.item())\n",
        "    learning_history_torch['accuracy_train'].append(train_accuracy.item())\n",
        "    learning_history_torch['accuracy_test'].append(test_accuracy.item())\n",
        "    learning_history_torch['W1_norm'].append(W1_norm)\n",
        "    learning_history_torch['W2_norm'].append(W2_norm)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch:3d}, Loss: {loss.item():.4f}, Train Acc: {train_accuracy.item():.4f}, Test Acc: {test_accuracy.item():.4f}')"
      ],
      "metadata": {
        "id": "d8rrayfkJfht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Визуализация процесса обучения НС"
      ],
      "metadata": {
        "id": "dhnu7xV6KouH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "# Loss\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(learning_history_torch['loss'], 'b-', linewidth=2)\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend(['Loss'])\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(learning_history_torch['accuracy_train'], 'g-', linewidth=2, label='Train')\n",
        "plt.plot(learning_history_torch['accuracy_test'], 'r-', linewidth=2, label='Test')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Weights\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(learning_history_torch['W1_norm'], 'purple', linewidth=2, label='||W1||')\n",
        "plt.plot(learning_history_torch['W2_norm'], 'orange', linewidth=2, label='||W2||')\n",
        "plt.title('Weights')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Weights')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)"
      ],
      "metadata": {
        "id": "aqmrM-dbLKCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decision_boundary(model, X, y):\n",
        "    \"\"\"Визуализация границы принятия решений нейронной сети\"\"\"\n",
        "    h = 0.02\n",
        "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
        "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        X_grid = torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()])\n",
        "        Z = model(X_grid)\n",
        "        Z = (Z > 0.5).float().numpy()\n",
        "\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.RdBu)\n",
        "    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdBu, edgecolors='black', s=30)\n",
        "    plt.colorbar(scatter)\n",
        "    plt.show()\n",
        "\n",
        "plot_decision_boundary(model_nn_torch, X_test_scaled, Y_test)"
      ],
      "metadata": {
        "id": "pzFujZ2hLYk-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}